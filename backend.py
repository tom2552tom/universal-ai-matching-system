import streamlit as st
import sqlite3
import faiss
from sentence_transformers import SentenceTransformer
import numpy as np
import os
import google.generativeai as genai
import json
from datetime import datetime
import imaplib
import email
from email.header import decode_header
import io
import contextlib
import toml
import fitz
import docx

# --- 1. åˆæœŸè¨­å®šã¨å®šæ•° ---
try:
    API_KEY = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=API_KEY)
except (KeyError, Exception):
    st.error("`secrets.toml` ã« `GOOGLE_API_KEY` ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

DB_FILE = "backend_system.db"
JOB_INDEX_FILE = "backend_job_index.faiss"
ENGINEER_INDEX_FILE = "backend_engineer_index.faiss"
MODEL_NAME = 'intfloat/multilingual-e5-large'
TOP_K_CANDIDATES = 50
MIN_SCORE_THRESHOLD = 70.0 # æ¨å¥¨å€¤ã«è¨­å®š

@st.cache_data
def load_app_config():
    try:
        with open("config.toml", "r", encoding="utf-8") as f: return toml.load(f)
    except FileNotFoundError: return {"app": {"title": "Universal AI Agent"}}

@st.cache_resource
def load_embedding_model():
    try: return SentenceTransformer(MODEL_NAME)
    except Exception as e: st.error(f"åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ« '{MODEL_NAME}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"); return None


# backend.py

# â–¼â–¼â–¼ã€ã“ã®é–¢æ•°å…¨ä½“ã‚’ç½®ãæ›ãˆã¦ãã ã•ã„ã€‘â–¼â–¼â–¼
def init_database():
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’åˆæœŸåŒ–ã™ã‚‹ã€‚
    æ—¢å­˜ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚«ãƒ©ãƒ ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€ä¸è¶³ã—ã¦ã„ã‚‹ã‚«ãƒ©ãƒ ãŒã‚ã‚Œã°è¿½åŠ ã™ã‚‹ã€‚
    """
    conn = get_db_connection() # â˜…â˜…â˜… ä¿®æ­£ç‚¹: ç‹¬è‡ªã®æ¥ç¶šã§ã¯ãªãã€å…±é€šé–¢æ•°ã‚’ä½¿ç”¨
    cursor = conn.cursor()

    try:
        # --- åŸºæœ¬ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ ---
        cursor.execute('CREATE TABLE IF NOT EXISTS jobs (id INTEGER PRIMARY KEY AUTOINCREMENT, project_name TEXT, document TEXT NOT NULL, source_data_json TEXT, created_at TEXT)')
        cursor.execute('CREATE TABLE IF NOT EXISTS engineers (id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT, document TEXT NOT NULL, source_data_json TEXT, created_at TEXT)')
        cursor.execute('CREATE TABLE IF NOT EXISTS matching_results (id INTEGER PRIMARY KEY AUTOINCREMENT, job_id INTEGER, engineer_id INTEGER, score REAL, created_at TEXT, is_hidden INTEGER DEFAULT 0, FOREIGN KEY (job_id) REFERENCES jobs (id), FOREIGN KEY (engineer_id) REFERENCES engineers (id))')
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS users (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                username TEXT NOT NULL UNIQUE,
                email TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
        """)

        # --- åˆå›èµ·å‹•æ™‚ã®ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ  ---
        cursor.execute("SELECT COUNT(*) FROM users")
        if cursor.fetchone()['COUNT(*)'] == 0:
            print("åˆå›èµ·å‹•ã®ãŸã‚ã€ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¿½åŠ ã—ã¾ã™...")
            cursor.execute("INSERT INTO users (username, email) VALUES (?, ?)", ('ç†Šå´', 'yamada@example.com'))
            cursor.execute("INSERT INTO users (username, email) VALUES (?, ?)", ('å²©æœ¬', 'suzuki@example.com'))
            cursor.execute("INSERT INTO users (username, email) VALUES (?, ?)", ('å°é–¢', 'sato@example.com'))
            print(" -> 3åã®ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")

        # --- ã‚«ãƒ©ãƒ ã®è‡ªå‹•è¿½åŠ å‡¦ç† ---
        # (jobsãƒ†ãƒ¼ãƒ–ãƒ«)
        cursor.execute("PRAGMA table_info(jobs)")
        job_columns = [row['name'] for row in cursor.fetchall()] # â˜…â˜…â˜… ä¿®æ­£ç‚¹: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§ã¯ãªãåå‰ã§ã‚¢ã‚¯ã‚»ã‚¹
        if 'assigned_user_id' not in job_columns:
            cursor.execute("ALTER TABLE jobs ADD COLUMN assigned_user_id INTEGER REFERENCES users(id)")
        if 'is_hidden' not in job_columns:
            cursor.execute("ALTER TABLE jobs ADD COLUMN is_hidden INTEGER NOT NULL DEFAULT 0")

        # (engineersãƒ†ãƒ¼ãƒ–ãƒ«)
        cursor.execute("PRAGMA table_info(engineers)")
        engineer_columns = [row['name'] for row in cursor.fetchall()] # â˜…â˜…â˜… ä¿®æ­£ç‚¹: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§ã¯ãªãåå‰ã§ã‚¢ã‚¯ã‚»ã‚¹
        if 'assigned_user_id' not in engineer_columns:
            cursor.execute("ALTER TABLE engineers ADD COLUMN assigned_user_id INTEGER REFERENCES users(id)")
        if 'is_hidden' not in engineer_columns:
            cursor.execute("ALTER TABLE engineers ADD COLUMN is_hidden INTEGER NOT NULL DEFAULT 0")
            
        # (matching_resultsãƒ†ãƒ¼ãƒ–ãƒ«)
        cursor.execute("PRAGMA table_info(matching_results)")
        match_columns = [row['name'] for row in cursor.fetchall()] # â˜…â˜…â˜… ä¿®æ­£ç‚¹: ã‚¨ãƒ©ãƒ¼ç®‡æ‰€ã‚’ä¿®æ­£
        if 'proposal_text' not in match_columns:
            cursor.execute("ALTER TABLE matching_results ADD COLUMN proposal_text TEXT")
        if 'grade' not in match_columns:
            cursor.execute("ALTER TABLE matching_results ADD COLUMN grade TEXT")

        conn.commit()
        print("Database initialized and schema verified successfully.")

    except sqlite3.Error as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        conn.rollback() # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã¯å¤‰æ›´ã‚’å…ƒã«æˆ»ã™
    finally:
        conn.close() # â˜…â˜…â˜… ä¿®æ­£ç‚¹: æœ€å¾Œã«æ¥ç¶šã‚’é–‰ã˜ã‚‹



def get_db_connection():
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’å–å¾—ã—ã¾ã™ã€‚
    row_factoryã‚’è¨­å®šã—ã€ã‚«ãƒ©ãƒ åã§ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚
    """
    conn = sqlite3.connect(DB_FILE)
    # â–¼â–¼â–¼ã€ã“ã®ä¸€è¡Œã‚’è¿½åŠ ãƒ»ä¿®æ­£ã—ã¾ã™ã€‘â–¼â–¼â–¼
    conn.row_factory = sqlite3.Row
    # â–²â–²â–²ã€ã“ã®ä¸€è¡Œã‚’è¿½åŠ ãƒ»ä¿®æ­£ã—ã¾ã™ã€‘â–²â–²â–²
    return conn


#def get_db_connection():
#    conn = sqlite3.connect(DB_FILE); conn.row_factory = sqlite3.Row; return conn



def update_job_source_json(job_id, new_json_str):
    """
    æŒ‡å®šã•ã‚ŒãŸæ¡ˆä»¶IDã®source_data_jsonã‚’æ›´æ–°ã™ã‚‹ã€‚
    
    Args:
        job_id (int): æ›´æ–°å¯¾è±¡ã®æ¡ˆä»¶IDã€‚
        new_json_str (str): æ›´æ–°å¾Œã®æ–°ã—ã„JSONæ–‡å­—åˆ—ã€‚
        
    Returns:
        bool: æ›´æ–°ãŒæˆåŠŸã—ãŸå ´åˆã¯Trueã€å¤±æ•—ã—ãŸå ´åˆã¯Falseã€‚
    """
    conn = get_db_connection()
    try:
        sql = "UPDATE jobs SET source_data_json = ? WHERE id = ?"
        cur = conn.cursor()
        cur.execute(sql, (new_json_str, job_id))
        conn.commit()
        return True
    except sqlite3.Error as e:
        print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        conn.rollback() # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯å¤‰æ›´ã‚’å…ƒã«æˆ»ã™
        return False
    finally:
        if conn:
            conn.close()


def split_text_with_llm(text_content):
    model = genai.GenerativeModel('models/gemini-2.5-pro')
    try:
        with open('prompt.txt', 'r', encoding='utf-8') as f:
            prompt_template = f.read()
        prompt = prompt_template.replace('{text_content}', text_content)
    except FileNotFoundError:
        st.error("ã‚¨ãƒ©ãƒ¼: `prompt.txt` ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚`backend.py` ã¨åŒã˜å ´æ‰€ã«ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        return None
    generation_config = {"response_mime_type": "application/json"}
    safety_settings = {'HARM_CATEGORY_HARASSMENT': 'BLOCK_NONE', 'HARM_CATEGORY_HATE_SPEECH': 'BLOCK_NONE', 'HARM_CATEGORY_SEXUALLY_EXPLICIT': 'BLOCK_NONE', 'HARM_CATEGORY_DANGEROUS_CONTENT': 'BLOCK_NONE'}
    try:
        with st.spinner("LLMãŒãƒ†ã‚­ã‚¹ãƒˆã‚’è§£æãƒ»æ§‹é€ åŒ–ä¸­..."):
            response = model.generate_content(prompt, generation_config=generation_config, safety_settings=safety_settings)
        raw_text = response.text
        start_index = raw_text.find('{')
        end_index = raw_text.rfind('}')
        if start_index != -1 and end_index != -1 and start_index < end_index:
            json_str = raw_text[start_index : end_index + 1]
            return json.loads(json_str)
        else:
            st.error("LLMã®å¿œç­”ã‹ã‚‰æœ‰åŠ¹ãªJSONå½¢å¼ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"); st.error("LLMã‹ã‚‰ã®ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹:"); st.code(raw_text, language='text'); return None
    except Exception as e:
        st.error(f"LLMã«ã‚ˆã‚‹æ§‹é€ åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"); st.error("LLMã‹ã‚‰ã®ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹:");
        try: st.code(response.text, language='text')
        except NameError: st.text("ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å–å¾—ã«ã‚‚å¤±æ•—ã—ã¾ã—ãŸã€‚")
        return None

@st.cache_data # ã€ã“ã®ä¸€è¡Œã‚’è¿½åŠ ã™ã‚‹ã ã‘ã€‘
def get_match_summary_with_llm(job_doc, engineer_doc):
    model = genai.GenerativeModel('models/gemini-2.5-pro')
    prompt = f"""
ã‚ãªãŸã¯ã€çµŒé¨“è±Šå¯ŒãªITäººæç´¹ä»‹ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚
ã‚ãªãŸã®ä»•äº‹ã¯ã€æç¤ºã•ã‚ŒãŸã€Œæ¡ˆä»¶æƒ…å ±ã€ã¨ã€ŒæŠ€è¡“è€…æƒ…å ±ã€ã‚’æ¯”è¼ƒã—ã€å®¢è¦³çš„ã‹ã¤å…·ä½“çš„ãªãƒãƒƒãƒãƒ³ã‚°è©•ä¾¡ã‚’è¡Œã†ã“ã¨ã§ã™ã€‚
# çµ¶å¯¾çš„ãªãƒ«ãƒ¼ãƒ«
- `summary`ã¯æœ€ã‚‚é‡è¦ãªé …ç›®ã§ã™ã€‚çµ¶å¯¾ã«çœç•¥ã›ãšã€å¿…ãšS, A, B, C, Dã®ã„ãšã‚Œã‹ã®æ–‡å­—åˆ—ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
- ãƒã‚¸ãƒ†ã‚£ãƒ–ãªç‚¹ã‚„æ‡¸å¿µç‚¹ãŒä¸€ã¤ã‚‚ãªã„å ´åˆã§ã‚‚ã€ãã®æ—¨ã‚’æ­£ç›´ã«è¨˜è¼‰ã™ã‚‹ã‹ã€ç©ºã®ãƒªã‚¹ãƒˆ `[]` ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
# æŒ‡ç¤º
ä»¥ä¸‹ã®2ã¤ã®æƒ…å ±ã‚’åˆ†æã—ã€ãƒã‚¸ãƒ†ã‚£ãƒ–ãªç‚¹ã¨æ‡¸å¿µç‚¹ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚æœ€çµ‚çš„ã«ã€ç·åˆè©•ä¾¡ï¼ˆsummaryï¼‰ã‚’S, A, B, C, Dã®5æ®µéšã§åˆ¤å®šã—ã¦ãã ã•ã„ã€‚
- S: å®Œç’§ãªãƒãƒƒãƒ, A: éå¸¸ã«è‰¯ã„ãƒãƒƒãƒ, B: è‰¯ã„ãƒãƒƒãƒ, C: æ¤œè¨ã®ä½™åœ°ã‚ã‚Š, D: ãƒŸã‚¹ãƒãƒƒãƒ
# JSONå‡ºåŠ›å½¢å¼
{{
  "summary": "S, A, B, C, Dã®ã„ãšã‚Œã‹",
  "positive_points": ["ã‚¹ã‚­ãƒ«é¢ã§ã®åˆè‡´ç‚¹"],
  "concern_points": ["ã‚¹ã‚­ãƒ«é¢ã§ã®æ‡¸å¿µç‚¹"]
}}
---
# æ¡ˆä»¶æƒ…å ±
{job_doc}
---
# æŠ€è¡“è€…æƒ…å ±
{engineer_doc}
---
"""
    generation_config = {"response_mime_type": "application/json"}
    safety_settings = {'HARM_CATEGORY_HARASSMENT': 'BLOCK_NONE', 'HARM_CATEGORY_HATE_SPEECH': 'BLOCK_NONE', 'HARM_CATEGORY_SEXUALLY_EXPLICIT': 'BLOCK_NONE', 'HARM_CATEGORY_DANGEROUS_CONTENT': 'BLOCK_NONE'}
    try:
        with st.spinner("AIãŒãƒãƒƒãƒãƒ³ã‚°æ ¹æ‹ ã‚’åˆ†æä¸­..."):
            response = model.generate_content(prompt, generation_config=generation_config, safety_settings=safety_settings)
        raw_text = response.text
        start_index = raw_text.find('{')
        end_index = raw_text.rfind('}')
        if start_index != -1 and end_index != -1 and start_index < end_index:
            json_str = raw_text[start_index : end_index + 1]
            return json.loads(json_str)
        else:
            st.error("è©•ä¾¡ã®åˆ†æä¸­ã«LLMãŒæœ‰åŠ¹ãªJSONã‚’è¿”ã—ã¾ã›ã‚“ã§ã—ãŸã€‚"); st.code(raw_text); return None
    except Exception as e:
        st.error(f"æ ¹æ‹ ã®åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"); return None

def update_index(index_path, items):
    embedding_model = load_embedding_model()
    if not embedding_model or not items: return
    dimension = embedding_model.get_sentence_embedding_dimension()
    index_map = faiss.IndexIDMap(faiss.IndexFlatIP(dimension))
    ids = np.array([item['id'] for item in items], dtype=np.int64)
    bodies = [str(item['document']).split('\n---\n', 1)[-1] for item in items]
    texts_with_prefix = ["passage: " + body for body in bodies]
    embeddings = embedding_model.encode(texts_with_prefix, normalize_embeddings=True, show_progress_bar=False)
    index_map.add_with_ids(embeddings, ids)
    faiss.write_index(index_map, index_path)

def search(query_text, index_path, top_k=5):
    embedding_model = load_embedding_model()
    if not embedding_model or not os.path.exists(index_path): return [], []
    index = faiss.read_index(index_path)
    if index.ntotal == 0: return [], []
    query_body = query_text.split('\n---\n', 1)[-1]
    prefixed_query = "query: " + query_body
    query_vector = embedding_model.encode([prefixed_query], normalize_embeddings=True).reshape(1, -1)
    similarities, ids = index.search(query_vector, min(top_k, index.ntotal))
    valid_ids = [int(i) for i in ids[0] if i != -1]
    valid_similarities = [similarities[0][j] for j, i in enumerate(ids[0]) if i != -1]
    return valid_similarities, valid_ids

def get_records_by_ids(table_name, ids):
    if not ids: return []
    with get_db_connection() as conn:
        placeholders = ','.join('?' for _ in ids)
        query = f"SELECT * FROM {table_name} WHERE id IN ({placeholders})"
        results = conn.execute(query, ids).fetchall()
        results_map = {res['id']: res for res in results}
        return [results_map[id] for id in ids if id in results_map]

# â–¼â–¼â–¼ã€ã“ã“ã‹ã‚‰ãŒä¿®æ­£ç®‡æ‰€ã§ã™ã€‘â–¼â–¼â–¼
def run_matching_for_item(item_data, item_type, cursor, now_str):
    """
    æŒ‡å®šã•ã‚ŒãŸæ¡ˆä»¶ã¾ãŸã¯æŠ€è¡“è€…ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã€é¡ä¼¼å€™è£œã‚’æ¤œç´¢ã—ã€LLMã«ã‚ˆã‚‹è©•ä¾¡ã‚’è¡Œã£ãŸä¸Šã§ãƒãƒƒãƒãƒ³ã‚°çµæœã‚’DBã«ä¿å­˜ã™ã‚‹ã€‚
    LLMã®è©•ä¾¡ãŒ 'S', 'A', 'B', 'C' ã®å ´åˆã®ã¿DBã«ä¿å­˜ã—ã€'D', 'E' ãªã©ãã‚Œä»¥å¤–ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã€‚
    """
    # 1. æ¤œç´¢å¯¾è±¡ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ±ºå®š
    if item_type == 'job':
        query_text, index_path = item_data['document'], ENGINEER_INDEX_FILE
        candidate_table = 'engineers'
    else: # item_type == 'engineer'
        query_text, index_path = item_data['document'], JOB_INDEX_FILE
        candidate_table = 'jobs'

    # 2. Faissã«ã‚ˆã‚‹é¡ä¼¼åº¦æ¤œç´¢ã‚’å®Ÿè¡Œ
    similarities, ids = search(query_text, index_path, top_k=TOP_K_CANDIDATES)
    if not ids:
        st.write(f"â–¶ ID:{item_data['id']} ({item_type}) ã®é¡ä¼¼å€™è£œã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    # 3. æ¤œç´¢çµæœã®å€™è£œãƒ‡ãƒ¼ã‚¿ã‚’DBã‹ã‚‰ä¸€æ‹¬å–å¾—
    candidate_records = get_records_by_ids(candidate_table, ids)
    # IDã‚’ã‚­ãƒ¼ã«ã—ãŸè¾æ›¸ã«å¤‰æ›ã—ã¦é«˜é€Ÿã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
    candidate_map = {record['id']: record for record in candidate_records}

    st.write(f"â–¶ ID:{item_data['id']} ({item_type}) ã®é¡ä¼¼å€™è£œ {len(ids)}ä»¶ã‚’è©•ä¾¡ã—ã¾ã™ã€‚")

    # 4. å„å€™è£œã‚’ãƒ«ãƒ¼ãƒ—ã—ã¦è©•ä¾¡ã¨ä¿å­˜å‡¦ç†
    for sim, candidate_id in zip(similarities, ids):
        score = float(sim) * 100

        # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®ã‚¹ã‚³ã‚¢ãŒé–¾å€¤æœªæº€ã®å ´åˆã¯ã€LLMè©•ä¾¡ã‚’è¡Œã‚ãšã«ã‚¹ã‚­ãƒƒãƒ—
        if score < MIN_SCORE_THRESHOLD:
            continue

        candidate_record = candidate_map.get(candidate_id)
        if not candidate_record:
            st.write(f"  - å€™è£œID:{candidate_id} ã®ãƒ‡ãƒ¼ã‚¿ãŒDBã‹ã‚‰å–å¾—ã§ããªã‹ã£ãŸãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue

        # 5. LLMè©•ä¾¡ã®ãŸã‚ã®æ¡ˆä»¶ãƒ»æŠ€è¡“è€…æƒ…å ±ã‚’æº–å‚™
        if item_type == 'job':
            job_doc = item_data['document']
            engineer_doc = candidate_record['document']
            job_id = item_data['id']
            engineer_id = candidate_record['id']
        else: # item_type == 'engineer'
            job_doc = candidate_record['document']
            engineer_doc = item_data['document']
            job_id = candidate_record['id']
            engineer_id = item_data['id']

        # 6. LLMã«ã‚ˆã‚‹ãƒãƒƒãƒãƒ³ã‚°è©•ä¾¡ã‚’å®Ÿè¡Œ
        # ã“ã®é–¢æ•°ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€åŒã˜çµ„ã¿åˆã‚ã›ã®å ´åˆã¯é«˜é€Ÿã«çµæœãŒè¿”ã‚‹
        llm_result = get_match_summary_with_llm(job_doc, engineer_doc)

        # 7. LLMã®è©•ä¾¡çµæœã«åŸºã¥ã„ã¦DBã¸ã®ä¿å­˜ã‚’åˆ¤æ–­
        if llm_result and 'summary' in llm_result:
            grade = llm_result.get('summary')

            # SummaryãŒ 'S', 'A', 'B', 'C' ã®å ´åˆã®ã¿DBã«ä¿å­˜
            if grade in ['S', 'A', 'B', 'C']:
                cursor.execute(
                    'INSERT INTO matching_results (job_id, engineer_id, score, created_at, grade) VALUES (?, ?, ?, ?, ?)',
                    (job_id, engineer_id, score, now_str, grade)
                )
                st.write(f"  - å€™è£œID:{candidate_id} -> ãƒãƒƒãƒãƒ³ã‚°è©•ä¾¡: {grade} (ã‚¹ã‚³ã‚¢: {score:.2f}) ... âœ… DBã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
            else:
                # SummaryãŒ 'D', 'E' ã¾ãŸã¯ãã®ä»–ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                st.write(f"  - å€™è£œID:{candidate_id} -> ãƒãƒƒãƒãƒ³ã‚°è©•ä¾¡: {grade} (ã‚¹ã‚³ã‚¢: {score:.2f}) ... âŒ ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
        else:
            # LLMã‹ã‚‰ã®å¿œç­”ãŒä¸æ­£ã ã£ãŸå ´åˆ
            st.write(f"  - å€™è£œID:{candidate_id} -> LLMè©•ä¾¡ã«å¤±æ•—ã—ãŸãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
# â–²â–²â–²ã€ã“ã“ã¾ã§ãŒä¿®æ­£ç®‡æ‰€ã§ã™ã€‘â–²â–²â–²


def process_single_content(source_data: dict):
    if not source_data: st.warning("å‡¦ç†ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚"); return False
    valid_attachments_content = []
    for att in source_data.get('attachments', []):
        content = att.get('content', '')
        if content and not content.startswith("[") and not content.endswith("]"):
             valid_attachments_content.append(f"\n\n--- æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«: {att['filename']} ---\n{content}")
        else:
            st.write(f"âš ï¸ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ« '{att['filename']}' ã¯å†…å®¹ã‚’æŠ½å‡ºã§ããªã‹ã£ãŸãŸã‚ã€è§£æã‹ã‚‰é™¤å¤–ã—ã¾ã™ã€‚")
    full_text_for_llm = source_data.get('body', '') + "".join(valid_attachments_content)
    if not full_text_for_llm.strip(): st.warning("è§£æå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚"); return False
    parsed_data = split_text_with_llm(full_text_for_llm)
    if not parsed_data: return False
    new_jobs_data = parsed_data.get("jobs", []); new_engineers_data = parsed_data.get("engineers", [])
    if not new_jobs_data and not new_engineers_data: st.warning("LLMã¯ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ¡ˆä»¶æƒ…å ±ã¾ãŸã¯æŠ€è¡“è€…æƒ…å ±ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"); return False
    with get_db_connection() as conn:
        cursor = conn.cursor(); now_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        source_json_str = json.dumps(source_data, ensure_ascii=False, indent=2)
        newly_added_jobs, newly_added_engineers = [], []
        
        for item_data in new_jobs_data:
            doc = item_data.get("document")
            project_name = item_data.get("project_name", "åç§°æœªå®šã®æ¡ˆä»¶") # åå‰ã‚’å–å¾—
            if not (doc and str(doc).strip() and str(doc).lower() != 'none'): doc = full_text_for_llm
            meta_info = f"[å›½ç±è¦ä»¶: {item_data.get('nationality_requirement', 'ä¸æ˜')}] [é–‹å§‹æ™‚æœŸ: {item_data.get('start_date', 'ä¸æ˜')}]\n---\n"; full_document = meta_info + doc
            cursor.execute('INSERT INTO jobs (project_name, document, source_data_json, created_at) VALUES (?, ?, ?, ?)', (project_name, full_document, source_json_str, now_str));
            item_data['id'] = cursor.lastrowid; item_data['document'] = full_document; newly_added_jobs.append(item_data)
        
        for item_data in new_engineers_data:
            doc = item_data.get("document")
            engineer_name = item_data.get("name", "åç§°ä¸æ˜ã®æŠ€è¡“è€…") # åå‰ã‚’å–å¾—
            if not (doc and str(doc).strip() and str(doc).lower() != 'none'): doc = full_text_for_llm
            meta_info = f"[å›½ç±: {item_data.get('nationality', 'ä¸æ˜')}] [ç¨¼åƒå¯èƒ½æ—¥: {item_data.get('start_date', 'ä¸æ˜')}]\n---\n"; full_document = meta_info + doc
            cursor.execute('INSERT INTO engineers (name, document, source_data_json, created_at) VALUES (?, ?, ?, ?)', (engineer_name, full_document, source_json_str, now_str));
            item_data['id'] = cursor.lastrowid; item_data['document'] = full_document; newly_added_engineers.append(item_data)

        st.write("ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°ã—ã€ãƒãƒƒãƒãƒ³ã‚°å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
        all_jobs = conn.execute('SELECT id, document FROM jobs').fetchall()
        all_engineers = conn.execute('SELECT id, document FROM engineers').fetchall()
        if all_jobs: update_index(JOB_INDEX_FILE, all_jobs)
        if all_engineers: update_index(ENGINEER_INDEX_FILE, all_engineers)
        for new_job in newly_added_jobs: run_matching_for_item(new_job, 'job', cursor, now_str)
        for new_engineer in newly_added_engineers: run_matching_for_item(new_engineer, 'engineer', cursor, now_str)
    return True

def extract_text_from_pdf(file_bytes):
    try:
        with fitz.open(stream=file_bytes, filetype="pdf") as doc: text = "".join(page.get_text() for page in doc)
        return text if text.strip() else "[PDFãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå¤±æ•—: å†…å®¹ãŒç©ºã¾ãŸã¯ç”»åƒPDF]"
    except Exception as e: return f"[PDFãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}]"

def extract_text_from_docx(file_bytes):
    try:
        doc = docx.Document(io.BytesIO(file_bytes)); text = "\n".join([para.text for para in doc.paragraphs])
        return text if text.strip() else "[DOCXãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå¤±æ•—: å†…å®¹ãŒç©º]"
    except Exception as e: return f"[DOCXãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}]"

def get_email_contents(msg) -> dict:
    body_text = ""; attachments = []
    if msg.is_multipart():
        for part in msg.walk():
            content_type = part.get_content_type(); content_disposition = str(part.get("Content-Disposition"))
            if 'text/plain' in content_type and 'attachment' not in content_disposition:
                charset = part.get_content_charset()
                try: body_text += part.get_payload(decode=True).decode(charset if charset else 'utf-8', errors='ignore')
                except Exception: body_text += part.get_payload(decode=True).decode('utf-8', errors='ignore')
            if 'attachment' in content_disposition:
                raw_filename = part.get_filename()
                if raw_filename:
                    decoded_header = decode_header(raw_filename)
                    filename = "".join([s.decode(c or 'utf-8', 'ignore') if isinstance(s, bytes) else s for s, c in decoded_header])
                    st.write(f"ğŸ“„ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚")
                    file_bytes = part.get_payload(decode=True)
                    lower_filename = filename.lower()
                    if lower_filename.endswith(".pdf"): attachments.append({"filename": filename, "content": extract_text_from_pdf(file_bytes)})
                    elif lower_filename.endswith(".docx"): attachments.append({"filename": filename, "content": extract_text_from_docx(file_bytes)})
                    elif lower_filename.endswith(".txt"): attachments.append({"filename": filename, "content": file_bytes.decode('utf-8', errors='ignore')})
                    else: st.write(f"â„¹ï¸ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ã¯æœªå¯¾å¿œã®å½¢å¼ã®ãŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
    else:
        charset = msg.get_content_charset()
        try: body_text = msg.get_payload(decode=True).decode(charset if charset else 'utf-8', errors='ignore')
        except Exception: body_text = msg.get_payload(decode=True).decode('utf-8', errors='ignore')
    return {"body": body_text.strip(), "attachments": attachments}

def fetch_and_process_emails():
    log_stream = io.StringIO()
    try:
        with contextlib.redirect_stdout(log_stream):
            try: SERVER, USER, PASSWORD = st.secrets["EMAIL_SERVER"], st.secrets["EMAIL_USER"], st.secrets["EMAIL_PASSWORD"]
            except KeyError as e: st.error(f"ãƒ¡ãƒ¼ãƒ«ã‚µãƒ¼ãƒãƒ¼ã®æ¥ç¶šæƒ…å ±ãŒSecretsã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“: {e}"); return False, log_stream.getvalue()
            try: mail = imaplib.IMAP4_SSL(SERVER); mail.login(USER, PASSWORD); mail.select('inbox')
            except Exception as e: st.error(f"ãƒ¡ãƒ¼ãƒ«ã‚µãƒ¼ãƒãƒ¼ã¸ã®æ¥ç¶šã¾ãŸã¯ãƒ­ã‚°ã‚¤ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"); return False, log_stream.getvalue()
            total_processed_count = 0; checked_count = 0
            try:
                with st.status("æœ€æ–°ã®æœªèª­ãƒ¡ãƒ¼ãƒ«ã‚’å–å¾—ãƒ»å‡¦ç†ä¸­...", expanded=True) as status:
                    _, messages = mail.search(None, 'UNSEEN')
                    email_ids = messages[0].split()
                    if not email_ids: st.write("å‡¦ç†å¯¾è±¡ã®æœªèª­ãƒ¡ãƒ¼ãƒ«ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    else:
                        latest_ids = email_ids[::-1][:10]; checked_count = len(latest_ids)
                        st.write(f"æœ€æ–°ã®æœªèª­ãƒ¡ãƒ¼ãƒ« {checked_count}ä»¶ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚")
                        for i, email_id in enumerate(latest_ids):
                            _, msg_data = mail.fetch(email_id, '(RFC822)')
                            for response_part in msg_data:
                                if isinstance(response_part, tuple):
                                    msg = email.message_from_bytes(response_part[1])
                                    source_data = get_email_contents(msg)
                                    if source_data['body'] or source_data['attachments']:
                                        st.write(f"âœ… ãƒ¡ãƒ¼ãƒ«ID {email_id.decode()} ã¯å‡¦ç†å¯¾è±¡ã§ã™ã€‚è§£æã‚’é–‹å§‹ã—ã¾ã™...")
                                        if process_single_content(source_data):
                                            total_processed_count += 1; mail.store(email_id, '+FLAGS', '\\Seen')
                                    else: st.write(f"âœ–ï¸ ãƒ¡ãƒ¼ãƒ«ID {email_id.decode()} ã¯æœ¬æ–‡ã‚‚æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ç„¡ã„ãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                            st.write(f"({i+1}/{checked_count}) ãƒã‚§ãƒƒã‚¯å®Œäº†")
                    status.update(label="ãƒ¡ãƒ¼ãƒ«ãƒã‚§ãƒƒã‚¯å®Œäº†", state="complete")
            finally: mail.close(); mail.logout()
        if checked_count > 0:
            if total_processed_count > 0: st.success(f"ãƒã‚§ãƒƒã‚¯ã—ãŸ {checked_count} ä»¶ã®ãƒ¡ãƒ¼ãƒ«ã®ã†ã¡ã€{total_processed_count} ä»¶ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã€ä¿å­˜ã—ã¾ã—ãŸã€‚"); st.balloons()
            else: st.warning(f"ãƒ¡ãƒ¼ãƒ«ã‚’ {checked_count} ä»¶ãƒã‚§ãƒƒã‚¯ã—ã¾ã—ãŸãŒã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã§ãã‚‹æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else: st.info("å‡¦ç†å¯¾è±¡ã¨ãªã‚‹æ–°ã—ã„æœªèª­ãƒ¡ãƒ¼ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return True, log_stream.getvalue()
    except Exception as e:
        st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"); return False, log_stream.getvalue()

def hide_match(result_id):
    if not result_id: st.warning("éè¡¨ç¤ºã«ã™ã‚‹ãƒãƒƒãƒãƒ³ã‚°çµæœã®IDãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return False
    try:
        with get_db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute('UPDATE matching_results SET is_hidden = 1 WHERE id = ?', (result_id,))
            conn.commit()
            if cursor.rowcount > 0: st.toast(f"ãƒãƒƒãƒãƒ³ã‚°çµæœ (ID: {result_id}) ã‚’éè¡¨ç¤ºã«ã—ã¾ã—ãŸã€‚"); return True
            else: st.warning(f"ãƒãƒƒãƒãƒ³ã‚°çµæœ (ID: {result_id}) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"); return False
    except sqlite3.Error as e: st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ›´æ–°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"); return False
    except Exception as e: st.error(f"hide_matché–¢æ•°ã§äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"); return False

def get_all_users():
    """
    å…¨ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã€‚
    
    Returns:
        list: ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã®è¾æ›¸ã‚’è¦ç´ ã¨ã™ã‚‹ãƒªã‚¹ãƒˆã€‚
    """
    conn = get_db_connection()
    # conn.row_factory = sqlite3.Row ãŒ get_db_connection ã§è¨­å®šã•ã‚Œã¦ã„ã‚‹å‰æ
    users = conn.execute("SELECT id, username FROM users ORDER BY id").fetchall()
    conn.close()
    return users

def assign_user_to_job(job_id, user_id):
    """
    æ¡ˆä»¶ã«æ‹…å½“è€…ã‚’å‰²ã‚Šå½“ã¦ã‚‹ã€‚
    
    Args:
        job_id (int): å¯¾è±¡ã®æ¡ˆä»¶IDã€‚
        user_id (int or None): å‰²ã‚Šå½“ã¦ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®IDã€‚Noneã®å ´åˆã¯å‰²ã‚Šå½“ã¦è§£é™¤ã€‚
        
    Returns:
        bool: æ›´æ–°ãŒæˆåŠŸã—ãŸå ´åˆã¯Trueã€å¤±æ•—ã—ãŸå ´åˆã¯Falseã€‚
    """
    conn = get_db_connection()
    try:
        sql = "UPDATE jobs SET assigned_user_id = ? WHERE id = ?"
        cur = conn.cursor()
        cur.execute(sql, (user_id, job_id))
        conn.commit()
        return True
    except sqlite3.Error as e:
        print(f"æ‹…å½“è€…å‰²ã‚Šå½“ã¦ã‚¨ãƒ©ãƒ¼: {e}")
        conn.rollback()
        return False
    finally:
        if conn:
            conn.close()


def set_job_visibility(job_id, is_hidden):
    """
    æ¡ˆä»¶ã®è¡¨ç¤º/éè¡¨ç¤ºçŠ¶æ…‹ã‚’æ›´æ–°ã™ã‚‹ã€‚
    
    Args:
        job_id (int): å¯¾è±¡ã®æ¡ˆä»¶IDã€‚
        is_hidden (int): 0ãªã‚‰è¡¨ç¤ºã€1ãªã‚‰éè¡¨ç¤ºã€‚
        
    Returns:
        bool: æ›´æ–°ãŒæˆåŠŸã—ãŸå ´åˆã¯Trueã€å¤±æ•—ã—ãŸå ´åˆã¯Falseã€‚
    """
    conn = get_db_connection()
    try:
        sql = "UPDATE jobs SET is_hidden = ? WHERE id = ?"
        cur = conn.cursor()
        cur.execute(sql, (is_hidden, job_id))
        conn.commit()
        return True
    except sqlite3.Error as e:
        print(f"è¡¨ç¤ºçŠ¶æ…‹ã®æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        conn.rollback()
        return False
    finally:
        if conn:
            conn.close()

# ã€ã“ã“ã‹ã‚‰è¿½åŠ ã€‘ --- æŠ€è¡“è€…å‘ã‘ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰é–¢æ•° ---

def assign_user_to_engineer(engineer_id, user_id):
    """æŠ€è¡“è€…ã«æ‹…å½“è€…ã‚’å‰²ã‚Šå½“ã¦ã‚‹ã€‚"""
    conn = get_db_connection()
    try:
        cur = conn.cursor()
        cur.execute("UPDATE engineers SET assigned_user_id = ? WHERE id = ?", (user_id, engineer_id))
        conn.commit()
        return True
    except sqlite3.Error as e:
        print(f"æŠ€è¡“è€…ã¸ã®æ‹…å½“è€…å‰²ã‚Šå½“ã¦ã‚¨ãƒ©ãƒ¼: {e}"); conn.rollback(); return False
    finally:
        conn.close()

def set_engineer_visibility(engineer_id, is_hidden):
    """æŠ€è¡“è€…ã®è¡¨ç¤º/éè¡¨ç¤ºçŠ¶æ…‹ã‚’æ›´æ–°ã™ã‚‹ (0:è¡¨ç¤º, 1:éè¡¨ç¤º)ã€‚"""
    conn = get_db_connection()
    try:
        cur = conn.cursor()
        cur.execute("UPDATE engineers SET is_hidden = ? WHERE id = ?", (is_hidden, engineer_id))
        conn.commit()
        return True
    except sqlite3.Error as e:
        print(f"æŠ€è¡“è€…ã®è¡¨ç¤ºçŠ¶æ…‹ã®æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}"); conn.rollback(); return False
    finally:
        conn.close()

def update_engineer_source_json(engineer_id, new_json_str):
    """æŠ€è¡“è€…ã®source_data_jsonã‚’æ›´æ–°ã™ã‚‹ã€‚"""
    conn = get_db_connection()
    try:
        cur = conn.cursor()
        cur.execute("UPDATE engineers SET source_data_json = ? WHERE id = ?", (new_json_str, engineer_id))
        conn.commit()
        return True
    except sqlite3.Error as e:
        print(f"æŠ€è¡“è€…ã®JSONãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}"); conn.rollback(); return False
    finally:
        conn.close()


def generate_proposal_reply_with_llm(job_summary, engineer_summary, engineer_name, project_name):
    """
    LLMã‚’ä½¿ç”¨ã—ã¦ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¸ã®æŠ€è¡“è€…ææ¡ˆãƒ¡ãƒ¼ãƒ«æ–‡æ¡ˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚

    Args:
        job_summary (str): æ¡ˆä»¶ã®è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆã€‚
        engineer_summary (str): æŠ€è¡“è€…ã®è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆã€‚
        engineer_name (str): æŠ€è¡“è€…ã®åå‰ã€‚
        project_name (str): æ¡ˆä»¶åã€‚

    Returns:
        str: ç”Ÿæˆã•ã‚ŒãŸãƒ¡ãƒ¼ãƒ«æ–‡æ¡ˆã€ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚
    """


    # å¿…è¦ãªæƒ…å ±ãŒæƒã£ã¦ã„ã‚‹ã‹ç¢ºèª
    if not all([job_summary, engineer_summary, engineer_name, project_name]):
        return "æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€ææ¡ˆãƒ¡ãƒ¼ãƒ«ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

    # AIã¸ã®æŒ‡ç¤ºï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰
    prompt = f"""
ã‚ãªãŸã¯ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«å„ªç§€ãªæŠ€è¡“è€…ã‚’ææ¡ˆã™ã‚‹ã€çµŒé¨“è±Šå¯ŒãªITå–¶æ¥­æ‹…å½“è€…ã§ã™ã€‚
ä»¥ä¸‹ã®æ¡ˆä»¶æƒ…å ±ã¨æŠ€è¡“è€…æƒ…å ±ã‚’ã‚‚ã¨ã«ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å¿ƒã«éŸ¿ãã€ä¸å¯§ã§èª¬å¾—åŠ›ã®ã‚ã‚‹ææ¡ˆãƒ¡ãƒ¼ãƒ«ã®æ–‡é¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

# å½¹å‰²
- å„ªç§€ãªITå–¶æ¥­æ‹…å½“è€…

# æŒ‡ç¤º
- æœ€åˆã«ã€ææ¡ˆã™ã‚‹æŠ€è¡“è€…åã¨æ¡ˆä»¶åã‚’è¨˜è¼‰ã—ãŸä»¶åã‚’ä½œæˆã—ã¦ãã ã•ã„ (ä¾‹: ä»¶å: ã€ã€‡ã€‡æ§˜ã®ã”ææ¡ˆã€‘ã€‡ã€‡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä»¶)ã€‚
- æŠ€è¡“è€…ã®ã‚¹ã‚­ãƒ«ã‚„çµŒé¨“ãŒã€æ¡ˆä»¶ã®ã©ã®è¦ä»¶ã«å…·ä½“çš„ã«ãƒãƒƒãƒã—ã¦ã„ã‚‹ã‹ã‚’æ˜ç¢ºã«ç¤ºã—ã¦ãã ã•ã„ã€‚
- ãƒã‚¸ãƒ†ã‚£ãƒ–ãªç‚¹ï¼ˆé©åˆã‚¹ã‚­ãƒ«ï¼‰ã‚’å¼·èª¿ã—ã€æŠ€è¡“è€…ã®é­…åŠ›ã‚’æœ€å¤§é™ã«ä¼ãˆã¦ãã ã•ã„ã€‚
- æ‡¸å¿µç‚¹ï¼ˆã‚¹ã‚­ãƒ«ãƒŸã‚¹ãƒãƒƒãƒã‚„çµŒé¨“ä¸è¶³ï¼‰ãŒã‚ã‚‹å ´åˆã¯ã€æ­£ç›´ã«è§¦ã‚Œã¤ã¤ã‚‚ã€å­¦ç¿’æ„æ¬²ã‚„é¡ä¼¼çµŒé¨“ã€ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ãªã©ã§ã©ã®ã‚ˆã†ã«ã‚«ãƒãƒ¼ã§ãã‚‹ã‹ã‚’å‰å‘ãã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
- å…¨ä½“ã¨ã—ã¦ã€ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‹ã¤ä¸å¯§ãªãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒ¼ãƒ«ã®ãƒˆãƒ¼ãƒ³ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚
- æœ€å¾Œã«ã€ãœã²ä¸€åº¦ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§ã®é¢è«‡ã®æ©Ÿä¼šã‚’è¨­ã‘ã¦ã„ãŸã ã‘ã¾ã™ã‚ˆã†ãŠé¡˜ã„ã™ã‚‹ä¸€æ–‡ã§ç· ã‚ããã£ã¦ãã ã•ã„ã€‚
- å‡ºåŠ›ã¯ã€ä»¶åã¨æœ¬æ–‡ã‚’å«ã‚“ã ãƒ¡ãƒ¼ãƒ«å½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã¨ã—ã¦ãã ã•ã„ã€‚ä½™è¨ˆãªè§£èª¬ã¯ä¸è¦ã§ã™ã€‚

# æ¡ˆä»¶æƒ…å ±
{job_summary}

# æŠ€è¡“è€…æƒ…å ±
{engineer_summary}

# ææ¡ˆã™ã‚‹æŠ€è¡“è€…ã®åå‰
{engineer_name}

# æ¡ˆä»¶å
{project_name}

---
ãã‚Œã§ã¯ã€ä¸Šè¨˜ã®æŒ‡ç¤ºã«åŸºã¥ã„ã¦ã€æœ€é©ãªææ¡ˆãƒ¡ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""

    try:
        # st.secretsç­‰ã§APIã‚­ãƒ¼ã‚’ç®¡ç†ã—ã¦ã„ã‚‹ã“ã¨ã‚’æƒ³å®š
        # genai.configure(api_key=st.secrets["google_api_key"])
        #model = genai.GenerativeModel('gemini-2.5-pro')
        model = genai.GenerativeModel('models/gemini-2.5-pro')
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        # æœ¬ç•ªç’°å¢ƒã§ã¯ logging ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™
        print(f"Error generating proposal reply with LLM: {e}")
        return f"ææ¡ˆãƒ¡ãƒ¼ãƒ«ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"



def save_match_grade(match_id, grade):
    """
    æŒ‡å®šã•ã‚ŒãŸãƒãƒƒãƒãƒ³ã‚°IDã«å¯¾ã—ã¦ã€AIè©•ä¾¡ã®ç­‰ç´šã‚’ä¿å­˜ã—ã¾ã™ã€‚

    Args:
        match_id (int): matching_resultsãƒ†ãƒ¼ãƒ–ãƒ«ã®IDã€‚
        grade (str): ä¿å­˜ã™ã‚‹è©•ä¾¡ï¼ˆ'A', 'B'ãªã©ï¼‰ã€‚

    Returns:
        bool: ä¿å­˜ãŒæˆåŠŸã—ãŸå ´åˆã¯Trueã€å¤±æ•—ã—ãŸå ´åˆã¯Falseã€‚
    """
    if not grade:  # gradeãŒç©ºã®å ´åˆã¯ä½•ã‚‚ã—ãªã„
        return False
        
    conn = None
    try:
        conn = get_db_connection()
        conn.execute(
            "UPDATE matching_results SET grade = ? WHERE id = ?",
            (grade, match_id)
        )
        conn.commit()
        return True
    except Exception as e:
        print(f"Error saving match grade for match_id {match_id}: {e}")
        if conn:
            conn.rollback()
        return False
    finally:
        if conn:
            conn.close()